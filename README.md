# ğŸ Snake Game com InteligÃªncia Artificial (Reinforcement Learning)

Este projeto implementa o clÃ¡ssico **Jogo da Cobrinha** (Snake Game) controlado por uma **InteligÃªncia Artificial** treinada com **Aprendizado por ReforÃ§o** usando a biblioteca [Stable-Baselines3](https://stable-baselines3.readthedocs.io/).

---

## ğŸš€ Funcionalidades

- ğŸ® ImplementaÃ§Ã£o completa do jogo da cobrinha com **Pygame**.
- ğŸ§  Ambiente compatÃ­vel com **Gymnasium** para treino de IA.
- ğŸ¤– Treinamento usando **A2C** (Advantage Actor-Critic) â€” modelo facilmente adaptÃ¡vel para outros algoritmos como DQN, PPO, etc.
- ğŸ“Š Registro automÃ¡tico de **pontuaÃ§Ã£o** e **nÃºmero de movimentos** por jogo.
- ğŸ“ˆ Ferramenta grÃ¡fica para **visualizaÃ§Ã£o de desempenho** (pontuaÃ§Ãµes e movimentos ao longo do treino).
- ğŸ›  Estrutura modular para facilitar ajustes e testes.

---

## ğŸ“‚ Estrutura do Projeto

```
ğŸ“ snake_ai_project/
â”œâ”€â”€ learning_data.py      # VisualizaÃ§Ã£o dos resultados de treino em grÃ¡ficos
â”œâ”€â”€ snake_env.py          # DefiniÃ§Ã£o do ambiente Gymnasium
â”œâ”€â”€ snake_game.py         # ImplementaÃ§Ã£o do jogo com Pygame
â”œâ”€â”€ train_snake.py        # Script para treino e visualizaÃ§Ã£o da IA
â”œâ”€â”€ scores.txt            # Registro de pontuaÃ§Ãµes e movimentos
â””â”€â”€ snake_model.zip       # Modelo treinado (gerado apÃ³s treino)
```

---

## ğŸ–¥ Ambiente e Tecnologias

- **Linguagem:** Python 3.8+
- **Bibliotecas:**
  - `pygame` ğŸ® - motor grÃ¡fico do jogo
  - `gymnasium` ğŸ‹ï¸ - interface padrÃ£o de ambientes de RL
  - `stable-baselines3` ğŸ¤– - algoritmos de aprendizado por reforÃ§o
  - `matplotlib` ğŸ“Š - visualizaÃ§Ã£o de dados
  - `numpy` ğŸ”¢ - cÃ¡lculos numÃ©ricos

---

## ğŸ§© Componentes do Projeto

### 1ï¸âƒ£ `snake_game.py`
- ContÃ©m toda a **lÃ³gica do jogo**.
- Implementa funÃ§Ãµes para:
  - Resetar o jogo (`reset_game`)
  - Renderizar o estado atual (`render_game`)
  - Processar aÃ§Ãµes (`snake_action`)
- Usa **coordenadas relativas** para aÃ§Ãµes (frente, esquerda, direita) em vez de direÃ§Ãµes absolutas.

### 2ï¸âƒ£ `snake_env.py`
- Implementa a classe `SnakeEnv` compatÃ­vel com **Gymnasium**.
- Define:
  - `observation_space` e `action_space`
  - Sistema de **recompensas** baseado em:
    - Comer comida ğŸ (+50)
    - Movimento seguro
    - ColisÃ£o (-100)
    - Proximidade da comida (recompensa/deduÃ§Ã£o proporcional)
- Registra pontuaÃ§Ãµes e movimentos no arquivo `scores.txt`.

### 3ï¸âƒ£ `learning_data.py`
- LÃª `scores.txt` e plota grÃ¡ficos interativos de:
  - ğŸ“ˆ EvoluÃ§Ã£o da **pontuaÃ§Ã£o**
  - ğŸƒ EvoluÃ§Ã£o da **quantidade de movimentos**
- Possui botÃµes para alternar entre os grÃ¡ficos.

### 4ï¸âƒ£ `train_snake.py`
- Configura e treina o modelo A2C.
- OpÃ§Ãµes para:
  - Treinar (`train()`)
  - Visualizar a IA jogando (`visual_gaming()`)
- Salva e carrega automaticamente o modelo em `snake_model.zip`.

---

## âš™ï¸ Como Executar

### 1ï¸âƒ£ Clonar o repositÃ³rio
```bash
git clone https://github.com/Gabrielnunesilva/snake_game.git
cd snake_game
```

### 2ï¸âƒ£ Instalar dependÃªncias
```bash
pip install pygame gymnasium stable-baselines3 matplotlib numpy
```

### 3ï¸âƒ£ Treinar o modelo
```bash
python train_snake.py
```

### 4ï¸âƒ£ Visualizar resultados
```bash
python learning_data.py
```
---

## ğŸ† TÃ©cnicas Utilizadas

- **Reinforcement Learning** com A2C
- FunÃ§Ã£o de recompensa personalizada
- ObservaÃ§Ãµes otimizadas com:
  - PercepÃ§Ã£o de perigo nas 3 direÃ§Ãµes
  - LocalizaÃ§Ã£o relativa da comida
  - NormalizaÃ§Ã£o das distÃ¢ncias
- Sistema de **sugestÃ£o de movimentos** para otimizar aÃ§Ãµes

---

## ğŸ“Œ ObservaÃ§Ãµes

- O ambiente foi projetado para permitir **substituiÃ§Ã£o do algoritmo** de aprendizado facilmente.

---

## ğŸ“œ LicenÃ§a
Este projeto Ã© livre para uso acadÃªmico e pessoal. ğŸ˜„


